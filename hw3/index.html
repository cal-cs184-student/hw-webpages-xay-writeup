<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Xay Hanmonty</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-xay-writeup/">cal-cs184-student/hw-webpages-xay-writeup</a>
		<br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-xhw3">cal-cs184-student/sp25-hw3-xhw3</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<strong>(TODO)</strong>
		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<strong>Ray Generation pipeline</strong>
		<pre><code>for each pixel (x,y):
    for each sample:
        // 1. Generate normalized coordinates
        x_norm = (x + random_offset) / width
        y_norm = (y + random_offset) / height

        // 2. Generate camera ray
        ray = camera->generate_ray(x_norm, y_norm)

        // 3. Trace ray through scene
        radiance = est_radiance_global_illumination(ray)</code></pre>
	<p style="text-align: justify;">
		For the triangle intersection, I used Möller-Trumbore algorithm
		which computes both the intersection point and barycentric coordinates in a single calculation. The algorithm starts by calculating two edge vectors of the triangle (<code>edge1</code> and <code>edge2</code>) from vertex v1. Then calculates a vector h as the cross product of the ray direction and edge2, 
		followed by calculating the determinant using the dot product of edge1 and h. If the determinant is close to zero, the ray is considered parallel to the triangle, and we return false. Otherwise, we proceed by calculating the vector s from vertex v1 to the ray origin and use 
		it to find the barycentric coordinates (beta and gamma) through a series of dot products and cross products. The third barycentric coordinate (alpha) is calculated as one minus the sum of beta and gamma. If any barycentric coordinate is negative or if their sum exceeds 1, the intersection point lies 
		outside the triangle, and we return false. At the end, we calculate the intersection distance t and verify it falls within the ray's valid range (min_t to max_t). 
	</p>

		<p>Here are some of the results from the Ray intersections:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part1/CBempty.png" width="400px"/>
				  <figcaption>CBempty</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part1/banana.png" width="400px"/>
				  <figcaption>banana</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part1/spheres_normal.png" width="400px"/>
				  <figcaption>CBspheres</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part1/cube_normal.png" width="400px"/>
				  <figcaption>cube</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		<strong>BVH construction algorithm</strong><br>
		For this method, I uses the Mean of Centroids heuristic along the axis with the largest extent. Below is the algorithm construction:
		<ol>
			<li>Create an empty bounding box and calculate the number of primitives</li>
			<li>Check if there are no primitives (size = 0)</li>
			<li>Iterate through all primitives to:
				<ul>
					<li>Expand the overall bounding box to include it</li>
					<li>Add the primitive's centroid to a running sum</li>
				</ul>
			</li>
			<li>Create a new BVH node with the computed bounding box</li>
			<li>Check if the number of primitives is small enough (≤ max_leaf_size)
				<ul><li>If true, create a leaf node by setting start and end iterators</li>
				<li>Return the leaf node (base case)</li></ul>
			</li>
			<li>Determine the axis with the largest extent:
				<ul>
					<li>Start with X-axis (axis = 0)</li>
					<li>If Y-extent > X-extent, switch to Y-axis (axis = 1)</li>
					<li>If Z-extent > current axis extent, switch to Z-axis (axis = 2)</li>
				</ul>
			</li>
			<li>Calculate the mean of all centroids by dividing the sum by the number of primitives</li>
			<li>Use the coordinate of this mean along the chosen axis as the split point</li>
			<li>Partition the primitives into two groups using std::partition:
				<ul>
					<li>Left group: centroids < split point</li>
					<li>Right group: centroids ≥ split point</li>
				</ul>
			</li>
			<li>Check if all primitives ended up on one side (middle = start or middle = end)
				<ul>
					<li>If true, fall back to a median split:</li>
					<li>Set middle to start + (size/2)</li>
					<li>Use std::nth_element to find the median primitive</li>
				</ul>
			</li>
			<li>Recursively construct both subtrees and return the completed node:
				<ul>
					<li>Build left subtree with primitives [start, middle)</li>
					<li>Build right subtree with primitives [middle, end)</li>
				</ul>
			</li>
		</ol>
		<p>Here are some of the results from the BVH construction:</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part2/image.png" width="400px"/>
				  <figcaption>BVH</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part2/cow_refactored.png" width="400px"/>
				  <figcaption>cow</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part2/maxplanck_final.png" width="400px"/>
				  <figcaption>Max Planck</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part2/CBlucy.png" width="400px"/>
				  <figcaption>CBlucy (Complex geometry)</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;" colspan="2">
				  <img src="../hw3/part2/dragon.png" width="400px"/>
				  <figcaption>Dragon</figcaption>
				</td>
			  </tr>
			</table>
			<br>
		</div>
		<strong>Compare rendering times on cows.dae vs maxplanck.dae</strong><br>
		For cow.dae (5,856 primitives) BVH contruction take 0.0008 sec while maxplanck.dae (50,801 primitives) take 0.0082 sec. This demonstrates the BVH's O(log n) traversal efficiency and For more complex geometry, the Stanford Dragon (105,120 primitives), rendering with BVH approximately 4.4 million rays per second take around 7.1 intersection tests per ray on average . If we compare that without BVH, each ray would need to test against every primitive requiring it's own primitive intersection test per ray. So, the spatial median split strategy proves effective, creating well-balanced trees that enable fast ray traversal while keeping the BVH construction time minimal. See the comparision below:
		<br><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part2/cow_number.png" width="400px"/>
				  <figcaption>Cow</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part2/maxplanck_number.png" width="400px"/>
				  <figcaption>Max Planck</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;" colspan="2">
				  <img src="../hw3/part2/dragon_number.png" width="400px"/>
				  <figcaption>Dragon</figcaption>
				</td>
			  </tr>
			</table>
			<br>
		</div>
		
		<h2>Part 3: Direct Illumination</h2>
		<strong>Part 3.1</strong><br>
		The function <code>Vector3D DiffuseBSDF::f</code> Calculates how much light is reflected from direction <code>wi</code> (incoming) to direction <code>wo</code> (outgoing), where it returns <code>reflectance / PI</code>. For <code>DiffuseBSDF::sample_f</code>, it generates a random incoming direction <code>wi</code> and returns the BSDF value for that direction.
		then return by calling <code>f(wo, *wi)</code>

		<br><br><strong>Part 3.2</strong><br>
		Given Ray &r and Intersection &isect , <code>PathTracer::zero_bounce_radiance</code> returns the light that reaches the camera without bouncing off any of the objects in the scene. This is only the light that is coming from the light source, I used the BSDF of the surface at the point of intersection and returned its emission. 
		Then, updated <code>est_radiance_global_illumination</code> to return the zero-bounce radiance instead of normal shading.

		<br><br><strong>Part 3.3: Direct Lighting with Uniform Hemisphere Sampling</strong><br>
		In this approach, I randomly sample directions in the hemisphere above the hit point and check if those directions hit a light source.
		<br><strong>The Algorithm Follows:</strong>
		<ol>
			<li>Sample a random direction in the hemisphere above the hit point</li>
			<li>Cast a ray in that direction to see if it hits anything</li>
			<li>If it hits a light source, calculate the contribution from that light</li>
			<li>Average multiple samples to get the final estimate</li>
		</ol>
		<br><strong>Implementation below:</strong>
		<code><pre>
Vector3D PathTracer::estimate_direct_lighting_hemisphere(const Ray &r, const Intersection &isect) {
	Matrix3x3 o2w;
	make_coord_space(o2w, isect.n);
	Matrix3x3 w2o = o2w.T();
	
	const Vector3D hit_p = r.o + r.d * isect.t;
	const Vector3D w_out = w2o * (-r.d);
	
	Vector3D L_out(0, 0, 0);	
	
	for (int i = 0; i < ns_area_light; i++) {
	double pdf;
	Vector3D w_in = hemisphereSampler->get_sample(&pdf);
	
	Vector3D w_in_world = o2w * w_in;
	
	Ray sample_ray(hit_p, w_in_world);
	sample_ray.min_t = EPS_F;
	
	Intersection light_isect;
	if (bvh->intersect(sample_ray, &light_isect)) {

		if (light_isect.bsdf->get_emission().norm2() > 0) {

		Vector3D L_i = light_isect.bsdf->get_emission();
		

		Vector3D f = isect.bsdf->f(w_out, w_in);
		
		double cos_theta = w_in.z;
		L_out += f * L_i * cos_theta / pdf;
		}
	}
	}
	
	L_out /= ns_area_light;
	
	return L_out;
}
		</pre></code>

		<br><br><strong>Part 3.4: Direct Lighting with Important Sampling Lights</strong><br>
		In this approach, I directly sample the light sources instead of random directions, this follow the same implementation as the previous part where it is much more efficient.
		<br><strong>The Algorithm Follows:</strong>
		<ol>
			<li>For each light source in the scene:</li>
			<li>Sample a point on the light</li>
			<li>Calculate the direction from the hit point to that light point</li>
			<li>Check if the path is unoccluded (no objects blocking the light)</li>
			<li>If unoccluded, calculate the contribution</li>
		</ol>
		<br><strong>Implementation below:</strong>
		<code><pre>
Vector3D PathTracer::estimate_direct_lighting_importance(const Ray &r, const Intersection &isect) {
Matrix3x3 o2w;
make_coord_space(o2w, isect.n);
Matrix3x3 w2o = o2w.T();

const Vector3D hit_p = r.o + r.d * isect.t;
const Vector3D w_out = w2o * (-r.d);

Vector3D L_out(0, 0, 0);

for (auto light : scene->lights) {
	int num_samples = light->is_delta_light() ? 1 : ns_area_light;
	
	Vector3D light_contribution(0, 0, 0);
	
	for (int i = 0; i < num_samples; i++) {
	Vector3D wi_world;
	double dist_to_light;
	double pdf;
	Vector3D light_intensity = light->sample_L(hit_p, &wi_world, &dist_to_light, &pdf);
	
	if (pdf < 1e-4 || light_intensity.norm2() < 1e-6) {
		continue;
	}
	
	Vector3D wi = w2o * wi_world;
	
	if (wi.z <= 0) {
		continue;
	}
	
	Ray shadow_ray(hit_p, wi_world);
	shadow_ray.min_t = EPS_F;
	shadow_ray.max_t = dist_to_light - EPS_F;
	
	Intersection shadow_isect;
	if (!bvh->intersect(shadow_ray, &shadow_isect)) {
		Vector3D f = isect.bsdf->f(w_out, wi);
		double cos_theta = wi.z;
		
		if (light->is_delta_light()) {
		light_contribution += f * light_intensity * cos_theta;
		} else {
		light_contribution += f * light_intensity * cos_theta / pdf;
		}
	}
	}
	
	if (num_samples > 0) {
	L_out += light_contribution / num_samples;
	}
}

return L_out;
}
		</pre></code>
		<br><br>
		<strong>Compare the results between uniform hemisphere sampling and lighting sampling</strong><br><br>
		The importance sampling method produces significantly cleaner images with less noise compared to uniform hemisphere sampling. This occurs because importance sampling focuses on sampling the actual light sources, while hemisphere sampling wastes computational effort by randomly sampling all directions, including those without light sources.
		<br><br>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part3/CBbunny_H_64_32.png" width="400px"/>
				  <figcaption>CBbunny.dae with hemisphere sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part3/bunny.png" width="400px"/>
				  <figcaption>CBbunny.dae with importance sampling</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="../hw3/part3/CBspheres_S.png" width="400px"/>
				  <figcaption>CBspheres.dae with hemisphere sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="../hw3/part3/CBspheres.png" width="400px"/>
				  <figcaption>CBspheres.dae with importance sampling</figcaption>
				</td>
			  </tr>
			</table>
			<br>
		</div>

		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		</div>
	</body>
</html>